{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d906a32-8ac3-49bc-a6e8-32a92919c8cc",
   "metadata": {},
   "source": [
    "機械学習を用いたLinear regressionの基本的な考え方とhaskellでの実装を示す。（Floatでやるべきかtensorでやるべきか。。）\n",
    "haskellでのコードは、すべて今回の問題設定に則ったvalidなデータのみが入力されることを想定している。\n",
    "\n",
    "その後hasktorchでの実装をみていく。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b554fae-c271-4895-92e7-dccd43cd2ffa",
   "metadata": {},
   "source": [
    "## 1. What is Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d35010-e870-4a4f-b051-209e8b3a8975",
   "metadata": {},
   "source": [
    "Let's consider the revenue estimation for a supermarket in front of a station.\n",
    "\n",
    "The table below shows revenue for 10 months and the items that affect it[<sup>1</sup>](#id_01):\n",
    "- The number of passengers (because there is a supermarket in front of the station) \n",
    "- The amount of goods.\n",
    "\n",
    "| month | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Revenue | 123 | 290 | 230 | 261 | 140 | 173 | 133 | 179 | 210 | 181 |\n",
    "| Passengers | 9.3K | 23K | 25K | 26K | 11.9K | 18.3K | 15.1K | 19.2K | 26.3K | 18.5K |\n",
    "| Goods | 150 | 311 | 182 | 245 | 152 | 162 | 99 | 184 | 115 | 105 |\n",
    "\n",
    "<!-- In order to predict it with machine learning, we need past revenue and past data items that can affect it. For example, in this case, the passenger of the station and Amount of goods is considered  -->\n",
    "\n",
    "<!-- With this data, we can see the relationship between revenue, passengers, and products for 10 months. In other words, we can obtain expression for them. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71245e53-1e46-44f2-8eb1-40f48318d9b2",
   "metadata": {},
   "source": [
    "In order to estimate revenue based on this data, we need to express those relationships using approximate formula. <br>\n",
    "In this case, revenue seems to be proportional to passengers and goods, so we'll analyze assuming that there is a linear relationship between them, which is called **Linear Regression**.[<sup>2</sup>](#id_02)\n",
    "\n",
    "To define an approximate expression, suppose that a set of month is $M=\\{1,\\dots,10\\}$, the number of passenger, the amount of goods and revenue are $(x_i)_{i\\in M},(y_i)_{i\\in M},(z_i)_{i\\in M}$. i.e. $(x_i)_{i\\in M}=(9.3,23,\\dots,18.5)$, $(y_i)_{i\\in M}=(150,311,\\dots,105)$, $(z_i)_{i\\in M}=(123,290,\\dots,181)$ <br>\n",
    "In linear regression, it is assumed that there is a [linear mapping](https://www.ucl.ac.uk/~ucahmto/0005_2021/Ch4.S14.html) expressed by <br>\n",
    "$z = a x + b y + c$<br>\n",
    "and each $z_i$ will be approximated by the value $ax_i+by_i+c$.\n",
    "\n",
    "Therefore, for estimating the revenue from passenger($x_j$) and good($y_j$) for a given month($j$), below linear function is used.\n",
    "$$\n",
    "f = ax_j+by_j+c\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c9603-5a73-4d2b-a8cc-e12f6df20e56",
   "metadata": {},
   "source": [
    "Now, let's define the data and the linear function in haskell.<br>\n",
    "This lecture use [Tensor type in hasktorch](https://hasktorch.github.io/tutorial/02-tensors.html), which is multidimensional array with a fixed shape and element type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d68f3f86-3aca-46eb-85be-4c48009ba14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- data\n",
    "import Torch.Tensor (Tensor, asTensor)\n",
    "\n",
    "z :: Tensor\n",
    "z = asTensor [[123, 290, 230, 261, 140, 173, 133, 179, 210, 181]]\n",
    "\n",
    "x :: Tensor\n",
    "x = asTensor [9300, 23000, 25000, 26000, 11900, 18300, 15100, 19200, 26300, 18500]\n",
    "y :: Tensor\n",
    "y = asTensor [150, 311, 182, 245, 152, 162, 99, 184, 115, 105]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac128a93-bae6-40a6-8ef8-3c3c54911ae9",
   "metadata": {},
   "source": [
    "Since they are handled as Tensor type, matrix operations are performed in the implementation for linear function.<br>\n",
    "Suppose that $s = [a, b]$ (1 × 2 matrix) and $v = [x, y]$　(2 × 10 matrix),\n",
    "$$\n",
    "f = s\\cdot v + c\n",
    "% \\begin{aligned}\n",
    "% \\mathcal{L} &= \\cfrac{1}{n(M)}\\sum_i(z_i - \\vec{p}\\cdot\\vec{v_i})^2 \\\\\n",
    "%             &= \\cfrac{1}{n(M)}\\sum_i(\\vec{p}\\cdot\\vec{v_i} - z_i)^2 \n",
    "% \\end{aligned}\n",
    "$$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dd73d5c5-b7b3-461c-98d8-7c5b1099250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Torch.Functional (matmul, add, transpose2D)\n",
    "-- | Predict revenue from the passengers and goods,\n",
    "linear :: \n",
    "    (Tensor, Tensor) -> -- ^ parameters ([a, b]: 1 × 2, c: scalar)\n",
    "    Tensor ->           -- ^ data (passengers, goods): 2 × 10\n",
    "    Tensor              -- ^ estimated value: 1 × 10\n",
    "linear (slope, intercept) input = (slope `matmul` input) `add` intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ba1847-ad78-4999-b9c9-d12231d67e14",
   "metadata": {},
   "source": [
    "Example when $a = 2$, $b = 3$, and $c = 4$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d2a84662-860a-4c33-89cb-a51bf996b3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor Double [1,10] [[ 115.9000   ,  262.5000   ,  222.9000   ,  254.1000   ,  132.3000   ,  174.7000   ,  130.3000   ,  188.9000   ,  203.9000   ,  153.1000   ]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Torch.Functional (Dim(..) , stack)\n",
    "sampleSlope = asTensor [[0.006, 0.4]]\n",
    "sampleIntercept = asTensor [0.1]\n",
    "\n",
    "sampleEstimation = linear (sampleSlope, sampleIntercept) (stack (Dim 0) [x, y])\n",
    "sampleEtimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d818785-1569-4279-824d-c3323b60696f",
   "metadata": {},
   "source": [
    "Here, we can now get an estimate of revenue given a passenger and goods for a given month. However, the parameters a, b, and c still remain unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5744c5-690b-4542-aa54-420fe2f1fe21",
   "metadata": {},
   "source": [
    "## 2. How can we get better parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127976b-c9c0-43f4-959f-1a7cded0a055",
   "metadata": {},
   "source": [
    "To estimate revenue more accurately, we need to obtain the parameters a, b, and c that best approximate the data. In other words, the parameters minimize the discrepancy between the actual data($z$) and the output of the expression($ax_i+by_i+c$). <br>\n",
    "There are multiple solution methods, but here we will analyze using machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1baa559-01f6-4827-b345-1d2a6c7fcc2c",
   "metadata": {},
   "source": [
    "TODO:  add graph like http://www2.toyo.ac.jp/~mihira/keizaitoukei2014/ols1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382aafbd-1428-4f9d-a741-cd257d01c3c8",
   "metadata": {},
   "source": [
    "The discrepancy of each data data is $|\\delta i|$, and we consider the sum of squares divided by the number of data (i.e. the number of month $= n(M)$) as the function to be minimized.<br>\n",
    "The function of sum of squares divided by the number of data is called **Mean Squared Error** and is often used in regression analysis. The function to be minimized is called **Loss Function($=\\mathcal{L}$)**.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L} &= \\cfrac{1}{n(M)}\\sum_i\\delta_i^2 \\\\\n",
    "            &= \\cfrac{1}{n(M)}\\sum_i(z_i - ax_i - by_i - c)^2 \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e801b-0b0d-49d3-b75e-3679bf78c5b7",
   "metadata": {},
   "source": [
    "This function can be defined in haskell as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7612520c-d887-4c43-84be-a388e1629fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Torch (size)\n",
    "import Prelude hiding (div)\n",
    "import Torch.Functional (pow, div)\n",
    "\n",
    "-- TODO: 微分するためには、a,b cそれぞれパラメータとして持っとく必要がある？\n",
    "\n",
    "loss ::\n",
    "    Tensor -> -- ^ actual values: 1 × 10\n",
    "    Tensor -> -- ^ estimated values: 1 × 10\n",
    "    Tensor    -- ^ loss: scalar\n",
    "loss z z' = pow 2 (z - z') `div` asTensor (size 1 z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa345f4-f32c-42b9-9773-6206ace85d47",
   "metadata": {},
   "source": [
    "The loss between z and `sampleEstimation` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "994a2565-cb3b-4af2-ae97-2db7003710c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor Double [1,10] [[ 5.0410   ,  75.6250   ,  5.0410   ,  4.7610   ,  5.9290   ,  0.2890   ,  0.7290   ,  9.8010   ,  3.7210   ,  77.8410   ]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss z sampleEstimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd3fe15-bfc7-4b28-bedc-511ae403b604",
   "metadata": {},
   "source": [
    "In order to minimize $\\mathcal{L}$, we partially differentiate $\\mathcal{L}$ by the parameters and find the value that points to the lowest point (minimum value). This value is called **Gradient** ($=\\nabla \\mathcal{L} $).\n",
    "$$\n",
    "\\nabla \\mathcal{L} = \\left (\\cfrac{\\partial \\mathcal{L}}{\\partial a}, \\cfrac{\\partial \\mathcal{L}}{\\partial b}, \\cfrac{\\partial \\mathcal{L}}{\\partial c} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b762206f-b86f-4ad9-bfcc-04d126e7191a",
   "metadata": {},
   "source": [
    "The function to calculate the gradient is as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9558f308-cd41-413f-aa87-a2cfe9ba2a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- | Calculate numerical gradient when the argument of f is x.\n",
    "-- it's partially differentiated for each elament of x.\n",
    "numericalGradient　::\n",
    "    (Tensor -> Tensor) -> -- ^ differentiated function\n",
    "    Tensor             -> -- ^ argument of the function\n",
    "    Tensor\n",
    "numericalGradient f x = \n",
    "    f (x `add` h) + f (x `add` h) / 2\n",
    "    where\n",
    "        h = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "79ebdff1-6b1a-4c6f-be31-0bc87433bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor Double [1,10] [[ 123.0000   ,  290.0000   ,  230.0000   ,  261.0000   ,  140.0000   ,  173.0000   ,  133.0000   ,  179.0000   ,  210.0000   ,  181.0000   ]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Torch.Tensor ((!), Slice(..))\n",
    "z ! Slice (0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3b062-e852-46e3-8de4-aae3b185ce95",
   "metadata": {},
   "source": [
    "You might think that it is a good idea to solve actual value to solve the equations. This is fine for linear regression, however for many real-world problems, the parameter space is so vast that finding the minimum point is difficult.<br>\n",
    "Therefore, machine learning uses optimization algorithm　that efficiently search for the minimum value.[<sup>3</sup>](#id_03) <br>\n",
    "Here we use the simplest one: **Gradient Descent**. This algorithm varies the parameters along the gradient by a certain distance. Then, repeat the process of finding the gradient and changing the parameters at the destination.\n",
    "That is, update the parameters as below:\n",
    "$$\n",
    "(a, b, c) = \\left (a - \\eta\\cfrac{\\partial \\mathcal{L}}{\\partial a}, b - \\eta\\cfrac{\\partial \\mathcal{L}}{\\partial b}, c - \\eta\\cfrac{\\partial \\mathcal{L}}{\\partial c} \\right)\n",
    "$$\n",
    "$\\eta$ represent the update amount which is called **Learning Rate**. This determines how far the parameter moves in one step. [<sup>4</sup>](#id_04)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bfe298-a8d1-4703-a43f-ee96f33b46bc",
   "metadata": {},
   "source": [
    "Then, let's write a code to estimate the revenue using functions we've defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee47325-57df-44d9-9e35-36b3837ce908",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientDiscent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9b367c-c9c9-4bdb-b86b-83d8ce012e6a",
   "metadata": {},
   "source": [
    "1. <span id=\"id_01\"> https://www.statweb.jp/method/kaiki-bunseki/senkeikaiki-jyu-case </span>\n",
    "2. <span id=\"id_02\">The method differs depending on the relationship assumed. (For more variation, see non-regression analysis](https://en.wikipedia.org/wiki/Nonlinear_regression))</span>\n",
    "3. <span id=\"id_03\">Of course, using an optimization algorithm does not always guarantee that we will actually get the minimum value. When a function is complex, it may fall into a local minimum. Various [optimization algorithm](https://d2l.ai/chapter_optimization/) have been developed to solve this problem.</span>\n",
    "4. <span id=\"id_04\">This is one of the manually defined hyperparameters, unlike parameters (a, b, and c).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5155b-c2fb-4a5c-8290-aa96df942b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef2e07b4-912e-4f27-8be4-81eb69b43340",
   "metadata": {},
   "source": [
    "参照\n",
    "http://www2.toyo.ac.jp/~mihira/keizaitoukei2014/ols1.pdf\n",
    "http://fs1.law.keio.ac.jp/~aso/ecnm/pp/reg2.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "mimetype": "text/x-haskell",
   "name": "haskell",
   "pygments_lexer": "Haskell",
   "version": "9.2.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
